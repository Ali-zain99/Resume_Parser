# text_processor.py - autogenerated template file
import re
import nltk
from typing import List, Set, Dict, Optional
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import logging

logger = logging.getLogger(__name__)

class TextProcessor:
    """Utility class for text processing and analysis"""
    
    def __init__(self):
        self._download_nltk_data()
        self.skill_keywords = self._load_skill_keywords()
        self.experience_patterns = self._load_experience_patterns()
    
    def _download_nltk_data(self):
        """Download required NLTK data"""
        try:
            nltk.data.find('tokenizers/punkt')
        except LookupError:
            nltk.download('punkt')
        
        try:
            nltk.data.find('corpora/stopwords')
        except LookupError:
            nltk.download('stopwords')
    
    def _load_skill_keywords(self) -> Set[str]:
        """Load common technical skills and keywords"""
        return {
            # Programming Languages
            'python', 'javascript', 'java', 'c++', 'c#', 'php', 'ruby', 'go', 'rust', 'swift',
            'kotlin', 'scala', 'r', 'matlab', 'sql', 'html', 'css', 'typescript',
            
            # Frameworks and Libraries
            'react', 'angular', 'vue', 'node.js', 'express', 'django', 'flask', 'spring',
            'laravel', 'ruby on rails', 'asp.net', 'tensorflow', 'pytorch', 'pandas',
            'numpy', 'scikit-learn', 'opencv', 'bootstrap', 'jquery',
            
            # Databases
            'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch', 'oracle',
            'sql server', 'sqlite', 'cassandra', 'dynamodb',
            
            # Cloud and DevOps
            'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'git', 'gitlab',
            'github', 'terraform', 'ansible', 'chef', 'puppet', 'nagios', 'prometheus',
            
            # Data Science and ML
            'machine learning', 'deep learning', 'data science', 'artificial intelligence',
            'natural language processing', 'computer vision', 'big data', 'hadoop',
            'spark', 'kafka', 'tableau', 'power bi', 'excel',
            
            # Soft Skills
            'leadership', 'communication', 'teamwork', 'problem solving', 'project management',
            'agile', 'scrum', 'time management', 'analytical thinking', 'creativity'
        }
    
    def _load_experience_patterns(self) -> List[str]:
        """Load regex patterns for experience extraction"""
        return [
            r'(\d+)\+?\s*years?\s*(?:of\s*)?(?:experience|exp)',
            r'(\d+)\+?\s*yrs?\s*(?:of\s*)?(?:experience|exp)',
            r'(\d+)\+?\s*years?\s*in',
            r'(\d+)\+?\s*years?\s*working',
            r'experience\s*(?:of\s*)?(\d+)\+?\s*years?',
            r'(\d+)\+?\s*years?\s*(?:hands-on|practical)',
        ]
    
    def clean_text(self, text: str) -> str:
        """Clean and normalize text"""
        if not text:
            return ""
        
        # Remove extra whitespace and newlines
        text = re.sub(r'\s+', ' ', text)
        
        # Remove special characters but keep letters, numbers, and basic punctuation
        text = re.sub(r'[^\w\s\-\.\,\(\)]', ' ', text)
        
        # Remove multiple spaces
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def extract_skills(self, text: str) -> List[str]:
        """Extract technical skills from text"""
        if not text:
            return []
        
        text_lower = text.lower()
        found_skills = []
        
        # Find skill keywords in text
        for skill in self.skill_keywords:
            # Use word boundaries for exact matches
            pattern = r'\b' + re.escape(skill.lower()) + r'\b'
            if re.search(pattern, text_lower):
                found_skills.append(skill)
        
        # Also look for common skill patterns
        skill_patterns = [
            r'\b([A-Za-z]+(?:\.[A-Za-z]+)*)\s*(?:programming|development|coding)',
            r'\b([A-Za-z]+(?:\s+[A-Za-z]+)*)\s*(?:framework|library|tool)',
            r'(?:proficient|experienced|skilled)\s+(?:in|with)\s+([A-Za-z\s\.,]+)',
        ]
        
        for pattern in skill_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                skills = [s.strip() for s in match.split(',')]
                found_skills.extend(skills)
        
        # Remove duplicates and clean
        unique_skills = list(set([skill.strip().lower() for skill in found_skills if skill.strip()]))
        return unique_skills
    
    def extract_years_of_experience(self, text: str) -> Optional[int]:
        """Extract years of experience from text"""
        if not text:
            return None
        
        text_lower = text.lower()
        years = []
        
        for pattern in self.experience_patterns:
            matches = re.findall(pattern, text_lower, re.IGNORECASE)
            for match in matches:
                try:
                    years.append(int(match))
                except ValueError:
                    continue
        
        # Return the maximum years found
        return max(years) if years else None
    
    def extract_education(self, text: str) -> List[str]:
        """Extract education information from text"""
        if not text:
            return []
        
        education_keywords = [
            'bachelor', 'master', 'phd', 'doctorate', 'degree', 'diploma',
            'certification', 'certificate', 'university', 'college',
            'b.s.', 'b.a.', 'm.s.', 'm.a.', 'mba', 'ph.d.'
        ]
        
        education = []
        text_lower = text.lower()
        
        # Split text into sentences for better extraction
        sentences = nltk.sent_tokenize(text)
        
        for sentence in sentences:
            sentence_lower = sentence.lower()
            if any(keyword in sentence_lower for keyword in education_keywords):
                education.append(sentence.strip())
        
        return education
    
    def calculate_text_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two texts using TF-IDF and cosine similarity"""
        if not text1 or not text2:
            return 0.0
        
        try:
            vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)
            tfidf_matrix = vectorizer.fit_transform([text1, text2])
            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
            return float(similarity)
        except Exception as e:
            logger.error(f"Error calculating text similarity: {str(e)}")
            return 0.0
    
    def calculate_skill_similarity(self, skill1: str, skill2: str) -> float:
        """Calculate similarity between two skills"""
        if not skill1 or not skill2:
            return 0.0
        
        skill1_clean = skill1.lower().strip()
        skill2_clean = skill2.lower().strip()
        
        # Exact match
        if skill1_clean == skill2_clean:
            return 1.0
        
        # Substring match
        if skill1_clean in skill2_clean or skill2_clean in skill1_clean:
            return 0.8
        
        # Use text similarity for partial matches
        return self.calculate_text_similarity(skill1_clean, skill2_clean)